replicaCount: 1

nodeSelector: {}

namespace: dip
moduleName: agent-factory

# 设置为dev则为开发模式.
runMode: release

enableSecurityContext: true
securityContext:
  runAsUser: 1001
  runAsGroup: 1001

image:
  registry: acr.aishu.cn
  service:
    repository: dip/agent-backend
    tag: data-581755
    pullPolicy: IfNotPresent

service:
  agentFactory:
    type: ClusterIP
    port: 13020
    nodePort: 31022
    ingress:
      enabled: true
      interface:
        path:
          - /api/agent-factory/v1
          - /api/agent-factory/v2
          - /api/agent-factory/v3
          - /api/agent-app/v1
  type: ClusterIP
  enableDualStack: false
  port: 13020
  language: zh-CN
  loggerOutput: stdout
  loggerLevel: info # 【详见：go.uber.org/zap@v1.27.0/zapcore/level.go】
  businessTimeOffset: 0
  # APP 配置
  streamDiffFrequency: 5
  # 是否保留老的APP路径
  keep_legacy_app_path: true
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 60
    failureThreshold: 10

env:
  language: en_US.UTF-8
  timezone: Asia/Shanghai
  disable_pms_check: false

depServices:
  class-443:
    ingressClass: class-443
  hydra:
    userMgnt:
      host: user-management-private
      port: 30980
    hydraPublic:
      host: hydra-public
      port: 4444
    hydraAdmin:
      host: hydra-admin
      port: 4445
  # 数据库连接配置
  rds:
    type: MYSQL
    host: mariadb-mariadb-cluster.resource
    port: 3330
    hostRead: mariadb-mariadb-cluster.resource
    portRead: 3330
    user: anyshare
    password: xxx
    database: adp
    maxConnections: 30
    maxReadConnections: 30
    dbCharset: utf8mb4
    timeout: 10
    readTimeout: 10
    writeTimeout: 10
  opensearch:
    read: "opensearch-read"
    write: "opensearch-write"
    host: "opensearch-master"
    port: "9200"
    user: "admin"
    password: xxx
  redis:
    connectType: sentinel
    connectInfo:
      masterGroupName: mymaster
      password: xxx
      sentinelHost: proton-redis-proton-redis-sentinel.resource
      sentinelPassword: xxx
      sentinelPort: 26379
      sentinelUsername: root
      username: root
      host: ""
      port: ""
      masterHost: ""
      masterPort: 6379
      slaveHost: ""
      slavePort: 6379
    db: 3
    enableSSL: false
    secretName: ""
    caName: ""
    certName: ""
    keyName: ""
  mq:
    auth:
      mechanism: PLAIN
      password: xxx
      username: anyrobot
    connectorType: kafka
    mqHost: kafka-headless.resource.svc.cluster.local.
    mqLookupdHost: ""
    mqLookupdPort: 0
    mqPort: 9097
    mqType: kafka
    protocol: sasl_plaintext
    tenant: default
  modelFactory:
    model_api_svc:
      host: mf-model-api
      port: 9898
      protocol: http
    model_manager_svc:
      host: mf-model-manager
      port: 9898
      protocol: http
    llm:
      api_key: xxx
  ecoIndex:
    private_svc:
      host: ecoindex-private
      port: 32130
      protocol: http
  datahubcentral:
    private_svc:
      host: datahubcentral-private
      port: 9002
      protocol: http
  authorization:
    private_svc:
      host: authorization-private
      port: 30920
      protocol: http
    public_svc:
      host: authorization-public
      port: 30920
      protocol: http
  agentFactory:
    private_svc:
      host: agent-factory
      port: 13020
      protocol: http
  bizDomain:
    private_svc:
      host: business-system-service
      port: 80
      protocol: http
  # APP 特有服务
  agentExecutor:
    public_svc:
      host: agent-executor-public
      port: 30778
      protocol: http
    private_svc:
      host: agent-executor
      port: 30778
      protocol: http
    use_v2: true
  efast:
    private_svc:
      host: efast-private
      port: 9123
      protocol: http
    public_svc:
      host: efast-public
      port: 9123
      protocol: http
  docset:
    public_svc:
      host: docset-public
      port: 32596
      protocol: http
    private_svc:
      host: docset-private
      port: 32597
      protocol: http
  ecoconfig:
    private_svc:
      host: ecoconfig-private
      port: 32128
      protocol: http
    public_svc:
      host: ecoconfig-public
      port: 32127
      protocol: http
  uniquery:
    public_svc:
      host: mdl-uniquery-svc
      port: 13011
      protocol: http
    private_svc:
      host: mdl-uniquery-svc
      port: 13011
      protocol: http
  # ========== Sandbox Platform 配置 ==========
  sandboxPlatform:
    public_svc:
      host: sandbox-platform-public
      port: 8000
      protocol: http
    private_svc:
      host: sandbox-platform-private
      port: 8000
      protocol: http
    default_ttl: 3600         # 默认 Session TTL（秒），最大 3600
    max_retries: 10           # 等待 Session 就绪的最大重试次数
    retry_interval: "500ms"   # 重试间隔
    default_template_id: "python-basic"  # 默认模板 ID
    default_cpu: "1"          # 默认 CPU 核心数
    default_memory: "512Mi"   # 默认内存
    default_disk: "1Gi"       # 默认磁盘
    default_timeout: 300      # 默认超时时间（秒）
    file_upload_config:
      max_file_size: 10       # 最大文件大小（数值）
      max_file_size_unit: "MB"  # 单位：KB/MB/GB
      max_file_count: 10      # 最大文件数量
      allowed_file_types:     # 允许的文件类型
        - ".txt"
        - ".py"
        - ".js"
        - ".json"
        - ".csv"
        - ".md"
  # ========== LLM/Embedding 外部服务 (Executor/Memory共用) ==========
  llm_ad:
    embeddingUrl: ""
    embeddingModel: ""
    embeddingDimension: 768
  rerank_ad:
    rerankUrl: ""
  graphDatabase:
    type: "nebulaGraph"
    host: ""
    port: "9669"
    user: ""
    password: ""
    readonlyuser: ""
    readonlypassword: ""

resources:
  requests:
    cpu: 200m
    memory: 200Mi
  limits:
    cpu: 4
    memory: 8Gi

observability:
  logEnabled: true
  traceEnabled: false
  metricEnabled: false
  logExporter: http
  traceProvider: http
  metricProvider: http
  logLoadInternal: 1
  logLoadMaxLog: 10
  traceMaxQueueSize: 50000
  metricIntervalSecond: 60
  httpLogFeedIngesterUrl: http://feed-ingester-service:13031/api/feed_ingester/v1/jobs/dip-o11y-log/events
  httpTraceFeedIngesterUrl: http://feed-ingester-service:13031/api/feed_ingester/v1/jobs/dip-o11y-trace/events
  httpMetricFeedIngesterUrl: http://feed-ingester-service:13031/api/feed_ingester/v1/jobs/dip-o11y-metric/events
  grpcTraceFeedIngesterUrl: feed-ingester-service:30013
  grpcTraceJobId: dip-o11y-trace-grpc

# OpenTelemetry 配置 (新增)
opentelemetry:
  service_name: "agent-factory"
  service_version: "1.0.0"
  trace:
    enabled: false
    exporter: "console"
    http_endpoint: "http://localhost:4318/v1/traces"
    sampling_rate: 1.0
  log:
    enabled: false
    exporter: "console"
    http_endpoint: "http://localhost:4318/v1/logs"
    level: "info"
  metric:
    enabled: false
    exporter: "console"
    http_endpoint: "http://localhost:4318/v1/metrics"
    export_interval: 10

# ========== Agent Executor 配置 ==========
agentExecutor:
  port: 30778
  debugMode: false
  logLevel: "info"
  enableSystemLog: true
  enableDolphinAgentVerbose: false
  isPrintLastCommitInfo: true
  logConversationSessionInit: false
  isWriteExceptionLogToFile: false
  enableSensitiveWordDetection: false
  doNotUseExploreBlockV2: false
  disableDolphinSdkLLMCache: false
  enableDolphinAgentOutputVariablesCtrl: false
  isSkillAgentNeedProgress: false
  rps:
    limit: 100
  telemetry:
    log:
      enabled: false
      endpoint: ""
    metric:
      enabled: false
      endpoint: ""
    trace:
      enabled: false
      endpoint: ""

# ========== Agent Memory 配置 ==========
agentMemory:
  port: 30790
  llm:
    base_url: ""
    model: ""
  embedding:
    model: ""
    base_url: ""
    dims: 768
  rerank:
    model: ""
    url: ""
  telemetry:
    log:
      enabled: false
      endpoint: ""
    metric:
      enabled: false
      endpoint: ""
    trace:
      enabled: false
      endpoint: ""
